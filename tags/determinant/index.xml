<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>determinant on Runner</title>
    <link>/tags/determinant/</link>
    <description>Recent content in determinant on Runner</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Mon, 04 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/determinant/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Jacobi&#39;s formula</title>
      <link>/posts/2019-11-04-matrix-cookbook-46/</link>
      <pubDate>Mon, 04 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019-11-04-matrix-cookbook-46/</guid>
      <description>\[\tag{46}\frac{\partial \det \left( \mathbf{Y} \right)}{\partial x}=\,\,\det \left( \mathbf{Y} \right) Tr\left[ \mathbf{Y}^{-1}\frac{\partial \mathbf{Y}}{\partial x} \right] \]Formula \((46)\) is actually Jacobi’s formula. 1
Analogy in functions
For a differentiable function \(f: D\subseteq R\rightarrow R\), for all \(x\) in some neighborhood of \(a\), \(f\) can be written as: 2\[f(x)=f(a)+f^{\prime}(a) (x−a)+R(x−a) \]and, \(L(x)=f(a)+f^{\prime}(a)(x−a)\) is the best affine approximation of the function \(f\) at \(a\).
or, the idea could be expressed in other way:\[f(x+\epsilon)=f(x)+f^{\prime}(x) \epsilon +R\epsilon \]</description>
    </item>
    
    <item>
      <title>Derivative of log of determinant</title>
      <link>/posts/2019-10-30-matrix-cookbook-43/</link>
      <pubDate>Wed, 30 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019-10-30-matrix-cookbook-43/</guid>
      <description>\[\begin{equation}\tag{43}\partial(\ln (\operatorname{det}(\mathbf{X})))=\operatorname{Tr}\left(\mathbf{X}^{-1} \partial \mathbf{X}\right)\end{equation}\]
Lemma 1
\[\begin{equation}\sum_{i} \sum_{j} \mathbf{A}^{\mathrm{T}}_{i j} \mathbf{B}_{i j} = \operatorname{Tr}\left(\mathbf{A} \mathbf{B}\right)\end{equation}\]
Lemma 2 1
(Credit to https://statisticaloddsandends.wordpress.com/2018/05/24/derivative-of-log-det-x/)
\[\begin{equation}\frac{\partial(\operatorname{det} \mathbf{X})}{\partial \mathbf{X}_{i j}}=\mathbf{C}_{i j}\end{equation}\]
For a matrix \(X\), we define some terms:
The \((i,j)\) minor of \(X\), denoted \(M_{ij}\), is the determinant of the \((n-1) \times (n-1)\) matrix that remains after removing the \(i\)th row and \(j\)th column from \(X\).</description>
    </item>
    
    <item>
      <title>Matrix cookbook - determinant</title>
      <link>/posts/2019-10-17-matrix-cookbook-1.2-determinant/</link>
      <pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/posts/2019-10-17-matrix-cookbook-1.2-determinant/</guid>
      <description>\[\begin{equation}\tag{18}\operatorname{det}(\mathbf{A})=\prod_{i} \lambda_{i} \quad \lambda_{i}=\operatorname{eig}(\mathbf{A})\end{equation}\]
\[\begin{equation}\tag{19}\operatorname{det}(c \mathbf{A})=c^{n} \operatorname{det}(\mathbf{A}), \quad \text { if } \mathbf{A} \in \mathbb{R}^{n \times n}\end{equation}\]
\[\begin{equation}\tag{20}\operatorname{det}\left(\mathbf{A}^{T}\right)=\operatorname{det}(\mathbf{A})\end{equation}\]
\[\begin{equation}\tag{21}\operatorname{det}(\mathbf{A B})=\operatorname{det}(\mathbf{A}) \operatorname{det}(\mathbf{B})\end{equation}\]
The determinant of a tranformation matrix is the scale of area/volume of the shape before and after the tranformation. \(\mathbf{A B}\) are two consecutive transformations, therefore its determinant is the product of two scales.
\[\begin{equation}\tag{22}\operatorname{det}\left(\mathbf{A}^{-1}\right)=1 / \operatorname{det}(\mathbf{A})\end{equation}\]</description>
    </item>
    
  </channel>
</rss>